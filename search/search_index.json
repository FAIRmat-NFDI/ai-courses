{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Course on Big Data and  Artificial Intelligence in Materials Sciences","text":""},{"location":"#introduction-to-artificial-intelligence-and-machine-learning-methods","title":"Introduction to artificial intelligence and machine-learning methods","text":"<p>Speaker: Luca M. Ghiringhelli</p> <p>This introductory lecture covers a general overview of artificial intelligence methods, including machine-learning and data-mining methods. There is no hands-on notebook specifically associated to this lectures, but the concepts introduced therein can be useful to link together the various techniques presented in the next lectures.</p> <p>Video - Part 1 \u00a0  Video - Part 2 \u00a0 </p>"},{"location":"#regularized-regression-and-kernel-methods","title":"Regularized regression and kernel methods","text":"<p>Speaker: Santiago Rigamonti</p> <p>In this tutorial, we will explore the application of kernel ridge regression to the prediction of materials properties.</p> <p>Video - Part 1 \u00a0  Video - Part 2 \u00a0 </p> <p>Launch the notebook \u00a0 </p>"},{"location":"#decision-trees-and-random-forests","title":"Decision trees and random forests","text":"<p>Speaker: Daniel Speckhard</p> <p>In this tutorial, we will introduce decision trees. We go through a toy model introducing the SKLearn API. We then discuss step by step the different theoretical aspects of trees. We then move to training a regression tree and classification tree on different datasets related to materials science. We end the tutorial by covering random forests and bagging classfiers.</p> <p>Video - Part 1 \u00a0  Video - Part 2 \u00a0 </p> <p>Launch the notebook \u00a0 </p>"},{"location":"#artificial-neural-networks-and-deep-learning","title":"Artificial neural networks and deep learning","text":"<p>Speaker: Angelo Ziletti</p> <p>In these tutorials, we introduce the basic of deep learning, via tranditional multilayer perceptrons and modern convolutional neural networks.</p> <p>Video - Part 1 \u00a0  Video - Part 2 \u00a0 </p> <p>Launch the notebook 1 \u00a0  Launch the notebook 2 \u00a0 </p>"},{"location":"#unsupervised-learning","title":"Unsupervised learning","text":"<p>Speaker: Luigi Sbail\u00f2</p> <p>In this tutorial, we introduce to the most popular clustering algorithms. We focus on partitioning, hierarchical and density-based clustering algorithms. The methods are tested on synthetic datasets of increasing complexity.</p> <p>Video - Part 1 \u00a0  Video - Part 2 \u00a0 </p> <p>Launch the notebook 1 \u00a0  Launch the notebook 2 \u00a0 </p>"},{"location":"#compressed-sensing-meets-symbolic-regression-sisso","title":"Compressed sensing meets symbolic regression: SISSO","text":"<p>Speaker: Luca M. Ghiringhelli</p> <p>In this tutorial, we will show how to find descriptive parameters to predict materials properties using symbolic regrression combined with compressed sensing tools. The relative stability of the zincblende (ZB) versus rocksalt (RS) structure of binary materials is predicted and compared against a model trained with kernel ridge regression.</p> <p>Video - Part 1 \u00a0  Video - Part 2 \u00a0 </p> <p>Launch the notebook \u00a0 </p>"},{"location":"#subgroup-discovery-rare-phenomena-challenge-and-domain-of-applicability","title":"Subgroup discovery, rare-phenomena challenge, and domain of applicability","text":"<p>Speaker: Matthias Scheffler</p> <p>In these tutorials, we introduce the subgroup discovery (SGD) method, which identifies rules (Boolean statements involving selected features among the given candidates) describing exceptional subsets of data. SGD is an exploratory analysis tools and allows for identifying local structure in the data, while most ML tools focus on global models. A notable application of SGD is to locate the domain of applicability of ML models, i.e., identifying the property of data that are expected to yield significantly lower errors than the overall dataset. A notebook on this specific application is also linked.</p> <p>Video - Part 1 \u00a0  Video - Part 2 \u00a0 </p> <p>Launch the notebook 1 \u00a0  Launch the notebook 2 \u00a0 </p>"},{"location":"#fusion-of-experimental-and-computational-data-by-ai","title":"Fusion of experimental and computational data by AI","text":"<p>Speaker: Lucas Foppa</p> <p>In this tutorial, we provide an example of AI techniques combined to experiments, in such a way that the AI is trained on an initial set of data and the predictions of the trained model is used to guide the experiment in a similar but distinct class of materials.</p> <p>Video \u00a0 </p> <p>Launch the notebook \u00a0 </p>"}]}